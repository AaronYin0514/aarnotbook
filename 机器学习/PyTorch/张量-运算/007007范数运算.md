---
tags: python ai pytorch 
---

# 范数运算

## 范数

**范数，是具有“距离”概念的函数**。

> 距离的定义是一个宽泛的概念，只要满足**非负、自反、三角不等式就可以称之为距离。范数是一种强化了的距离概念**，它在定义上比距离多了一条**数乘**的运算法则。有时候为了便于理解，我们可以把范数当作距离来理解。


## 范数种类

- 0范数
- 1范数
- 2范数
- p范数
- 核范数

## 范数应用

- **定义loss**
- 参数约束，正则化等

## L-P范数

与闵可夫斯基距离的定义一样，L-P范数不是一个范数，而是一组范数

$$
L_p = ||x||_p = \sqrt[p]\sum_{i=1}^nx_i^p , x = (x_1,x_2,...,x_n)
$$

```python
a = torch.rand(1, 2) # tensor([[0.4770, 0.4915]])
torch.norm(a, p=3) # tensor(0.6103)
```

## L0范数

**L0范数度量向量中非0元素的个数**。

> L0范数不是一个真正的范数，根据公式，当$p = 0$，0的零次方，以及非0数开0次方没有意义，通常表示为:
> 
> $||x||_0 = \#(i|x_i \ne 0)$

```python
a = torch.tensor([[1.0,0,1],[2,0,2]])
torch.norm(a, p=0) # 4
```

## L1范数

**L1范数表示向量x中非零元素的绝对值之和。**L1范数也称曼哈顿距离，最小绝对误差等。

由于L1范数的天然性质，对L1优化的解是一个稀疏解， **因此L1范数也被叫做稀疏规则算子**。 **通过L1可以实现特征的稀疏，去掉一些没有信息的特征**。

$$
||x||_1 = \sum_{i=1}^n|x_i|
$$

```python
a = torch.rand(1, 2) # tensor([[0.7096, 0.2936]])
torch.norm(a, p=1) # tensor(1.0031)
```

**L1范数可以度量两个向量间的差异**，如绝对误差和。

$$
SAD(x_1,x_2) = \sum_i^n|x_{1i} - x_{2i}|
$$

```python
a = torch.rand(1, 2) # tensor([[0.7101, 0.1770]])
b = torch.rand(1, 2) # tensor([[0.1216, 0.2820]])

torch.dist(a, b, p=1) # tensor(0.6934)
```

## L2范数

**欧氏距离就是一种L2范数**

L2范数通常会被用来做优化目标函数的正则化项，防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。

$$
||x||_2 = \sum_{i=1}^nx_i^2
$$

```python
a = torch.rand(1, 2) # tensor([[0.9762, 0.1173]])

torch.norm(a) # tensor(0.9833)
```

**L2范数可以度量两个向量间的差异**，如平方差和。

$$
SAD(x_1,x_2) = \sum_i^n(x_{1i} - x_{2i})^2
$$

```python
a = torch.rand(1, 2) # tensor([[0.7781, 0.9901]])
b = torch.rand(1, 2) # tensor([[0.1071, 0.8938]])

torch.dist(a, b, p=2) # tensor(0.6779)
```


