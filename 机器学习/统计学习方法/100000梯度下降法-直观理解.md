# 梯度下降法-直观理解

> 直观理解并不严谨，意在快速理解

![](tiduxiajiangnn1.png)

## 梯度下降法

求解图中曲线的最小值。

设置一个**初始点**$x=3$做切线（导数，**梯度**），梯度的反方向就是数值下降最快的方向，沿着该方向慢慢逼近最小值点，就是梯度下降法。

如何逼近？函数$y$，梯度（一阶导数）$\nabla y = y'$，随机找一个初始值$x$，下一个$x = x - \alpha \nabla y$，如此往复计算$x$知道找到最优解。

其中$\alpha$的意义：如果每一次逼近的步子过大，那么很容易迈过最优解，所以设置一个**步长**，来控制每次逼近的步子。

## 例题

例：如图，求解$J(\theta) = \theta^2 + 2\theta + 5$的最小值。

> 很简单的数学题，答案是$\theta = -1$，如何利用梯度下降法求解？

计算**梯度**（一阶导数）：$\nabla J(\theta) = 2\theta + 2$

随机设置一个**初始值**：$\theta = 3$

设置一个**步长**：$\alpha = 0.06$

- 1）$\theta = \theta - \alpha \nabla J(\theta) = 3 - 0.06 * (2 * 3 + 2) = 2.52$
- 2）$\theta = \theta - \alpha \nabla J(\theta) = 2.52 - 0.06 * (2 * 2.52 + 2) = 2.0976$
- $\dots$
- 100）$\theta = \theta - \alpha \nabla J(\theta) = -0.9999887713587551$

可见，经过100次迭代，已经很接近答案了。

## 算法

1. 设置随机初始值$\theta$
2. 设置步长$\alpha$
3. 设置迭代此处$m$
4. 求解梯度$\nabla J(\theta)$
5. 计算

```
for i = 0 to m:
	θ = θ - ⍺∇J(θ)
```

## 注意

![](IMG_0870.JPG)

## 代码实现

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import font_manager

'''
求解 y = x^2 + 2x + 5 的最小值
'''

x = np.linspace(-6, 4, 100)
y = x ** 2 + 2 * x + 5
plt.plot(x, y, label='y = x^2 + 2x + 5')

'''
x2 = np.linspace(1, 4, 10)
y2 = 8 * x2 - 4
plt.plot(x2, y2, label='x=3处切线', color="#52c41a", linestyle="--")
'''

x = 3 # 随机初始值
alaph = 0.06 # 步长
iteraterNum = 100 # 迭代次数

'''
手动求导 y' = 2 * x + 2
'''

for i in range(iteraterNum):
  x = x - alaph * (2 * x + 2)
  print(x)
  y = x ** 2 + 2 * x + 5
  plt.scatter([x], [y], c='red')

my_font = font_manager.FontProperties(fname="/System/Library/Fonts/PingFang.ttc")
plt.legend(prop=my_font, loc="upper left")
plt.show()
```

## 参考资料

- [02-02-梯度下降法](https://www.bilibili.com/video/BV1zS4y1p7dV/?spm_id_from=333.880.my_history.page.click&vd_source=23d5ee46aa9f762104f00e96b4a39245)
- [02-03-梯度下降法代码实现](https://www.bilibili.com/video/BV1BZ4y1e7fB/?spm_id_from=333.788&vd_source=23d5ee46aa9f762104f00e96b4a39245)