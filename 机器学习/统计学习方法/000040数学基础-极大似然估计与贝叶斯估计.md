# 极大似然估计与贝叶斯估计

## 极大似然估计

设总体有分布$f(x;\theta_1,\dots\theta_k),X_1,\dots,X_n$为自这个总体找那个抽出的样本，则样本$(X_1,\dots,X_n)$的分布（即其概率密度函数［连续］或概率函数［离散］）为

$$
f(x_1;\theta_1,\dots\theta_k)f(x_2;\theta_1,\dots\theta_k)\dots f(x_n;\theta_1,\dots\theta_k)
$$

记为$L(x_1,\dots,x_n;\theta_1,\dots\theta_k)$

**固定**$\theta_1,\dots\theta_k$，而看做$x_1,\dots,x_n$的函数时，$L$是一个**概率密度函数**或**概率函数**。可以这样理解：若$L(Y_1,\dots,Y_n;\theta_1,\dots\theta_k)>L(X_1,\dots,X_n;\theta_1,\dots\theta_k)$。则在观察时出现$(Y_1,\dots,Y_n)$这个点的可能性要比出现$(X_1,\dots,X_n)$这个点的可能性大。

把这件事反过来说，可以这样想：当已观察到

$$
X_1,\dots,X_n时，若
$$

$$
L(X_1,\dots,X_n;\theta_1^{'},\dots,\theta_k^{'}) > L(X_1,\dots,X_n;\theta_1^{"},\dots,\theta_k^{"})
$$

则被估计的参数

$(\theta_1,\dots,\theta_k)$是$(\theta_1^{'},\dots,\theta_k^{'})$的可能性要比是$(\theta_1^{"},\dots,\theta_k^{"})$的可能性大

当$X_1,\dots,X_n$固定而把$L$看做$\theta_1,\dots,\theta_k$的函数时，它称为**似然函数**。这个名词的意义可根据上述分析得到理解：这个函数对不同的$(\theta_1,\dots,\theta_k)$的取值，反应了在观察结果$(X_1,\dots,X_n)$已知的条件下，$(\theta_1,\dots,\theta_k)$各种值的**似然程度**

这里有些像贝叶斯公式的推理：把观察值$(X_1,\dots,X_n)$看成结果，而把参数值$(\theta_1,\dots,\theta_k)$看成导致这个结果的原因，现已有了结果，要反过来，要反过来推算各种原因的概率。

这里、参数$(\theta_1,\dots,\theta_k)$有一定的值（虽然未知），且并非事件或随机变量，无概率可言，于是用**似然**这个词来描述。

由上述分析就自然地导出如下方法：应用似然程度最大的那个点$(\theta_1^{*},\dots,\theta_k^{*})$，即满足条件定义式

$$
L(x_1,\dots,X_n;\theta_1^{*},\dots,\theta_k^{*}) = \max_{\theta_1,\dots,\theta_k} L(X_1,\dots,X_n;\theta_1,\dots,\theta_k)的(\theta_1^{*},\dots,\theta_k^{*})
$$

去作为$(\theta_1,\dots,\theta_k)$的估计值，因为在已得样本$(X_1,\dots,X_n)$的条件下，这个"看起来最像"是真参数值。这个估计值$(\theta_1^{*},\dots,\theta_k^{*})$就叫做$(\theta_1,\dots,\theta_k)$的**极大似然估计**。如果要估计的是$g(\theta_1,\dots,\theta_k)$，则$g(\theta_1^{*},\dots,\theta_k^{*})$是他的极大似然估计。

因为：

$$
lnL = \sum_{i=1}^nlnf(X_i;\theta_1,\dots,\theta_k)
$$

且为了使$L$达到最大，只需要$lnL$达到最大，故在$f$对($\theta_1,\dots,\theta_k)$存在连续的偏导数时，可建立方程组（称为似然方程组）：

$$
\frac{\partial ln L}{\partial \theta_i} = 0(i=1,2,\dots,k)
$$

如果一个方程有唯一的解，又能验证它是一个极大值点，则它必是使$L$达到最大点的，即**极大似然估计**。

### 例1

设$(X_1,\dots,X_n)$是从正太总体$N(\mu, \sigma^2)$中抽取的样本，则似然函数为：

$$
L = \prod_{i=1}^n[(\sqrt{2\pi \sigma^2})^{-1} exp(-\frac{1}{2\sigma^2}(X_i-\mu)^2)]
$$

取自然对数：

$$
lnL = -\frac{n}{2}ln(2\pi) - \frac{n}{2}ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n(X_i - \mu)^2
$$

求解似然方程组：将$\sigma^2$看做整体

$$
\begin{cases}
\frac{\partial lnL}{\partial \mu}=\frac{1}{\sigma^2}\sum_{i=1}^n(X_i - \mu) = 0 \\
\frac{\partial lnL}{\partial \sigma^2}=-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n(X_i - \mu)^2 = 0
\end{cases}
$$

联立求解

$$
\begin{cases}
\frac{\partial lnL}{\partial \mu}=\frac{1}{\sigma^2}\sum_{i=1}^n(X_i - \mu) = 0 \\
\frac{\partial lnL}{\partial \sigma^2}=-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}\sum_{i=1}^n(X_i - \mu)^2 = 0
\end{cases}
$$

解得

$$
\begin{cases}
\mu^{*} = \sum_{i=1}^nX_i/n = \bar{X} \\
(\sigma^{*})^2=\sum_{i=1}^n(X_i-\bar{X})^2/n = B_k
\end{cases}
$$

【注意】有时，函数$f$并不对$(\theta_1,\dots,\theta_k)$可导，甚至$f$本身也不连续，这时方程组就无法应用，必须回到定义式进行求解。

可以确定$(\mu^{*},(\sigma^{*})^2)$确是使似然函数$L$达到最大值的点。因为似然方程组只有唯一的根$(\mu^{*},(\sigma^{*})^2)$，而这个点不可能是$L$的极小值点。因为由似然函数$L$可知：当$|\mu| \to \infty$或$\sigma^2 \to 0$，$L$趋于0，而$L$在每个点处都大于0

### 例2

设$(X_1,\dots,X_n)$是从指数分布总体中抽取的样本，求参数$\lambda$的极大似然估计

解

$$
L = \prod_{i=1}^n(\lambda e^{-lambda x_i})
$$

取自然对数

$$
lnL = nln(\lambda) - \lambda\sum_{i=1}^nX_i
$$

求解似然方程

$$
\frac{\partial lnL}{\partial \lambda} = \frac{\lambda}{n} - \sum_{i=1}^nX_i = 0
$$

解的$\lambda$的极大似然估计为：

$$
\lambda^{*} = n / \sum_{i=1}^nX_i = 1/ \bar{X}
$$


### 例3



## 置信区间

**置信区间**：概率等$a$，且以期望为中心的对称区域(在实际中$a$常常等于0.95或者0.99)；对于置信区间的两个边界值$x,y$他们的P-value 为$(1-a)/2$

![](../assets/imgs/ai/keneng.png)

在统计学中，P-value 小于 5%称为显著，小于1%称为极显著。我们可以通过参数的95%置信区间是否包含0来判断其是否显著（如果包含，则不显著）




